{"cells":[{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import re\n","import string\n","import joblib\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class ReduceMeanLayer(tf.keras.layers.Layer):\n","    def call(self, inputs):\n","        return tf.reduce_mean(inputs, axis=1)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["tokenizer_save_path = 'tokenizer.joblib'\n","model_save_path = 'best_lstm_model.keras'"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["tokenizer = joblib.load(tokenizer_save_path)\n","model = load_model(model_save_path, custom_objects={'ReduceMeanLayer': ReduceMeanLayer})"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def preprocess_text(text, tokenizer, max_length=100):\n","    text = text.lower()\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\w+|#\\w+', '', text)\n","    text = re.sub(r'@\\w+', '', text)\n","    text = re.sub(r'\\b\\d+\\b', '', text)\n","    text = ''.join([char for char in text if char not in string.punctuation])\n","    text = ' '.join([WordNetLemmatizer().lemmatize(word) for word in text.split() if word not in stopwords.words('english')])\n","    \n","    seq = tokenizer.texts_to_sequences([text])\n","    padded_seq = pad_sequences(seq, maxlen=max_length)\n","    \n","    return padded_seq"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def predict_text(text):\n","    processed_text = preprocess_text(text, tokenizer)\n","    prediction = model.predict(processed_text)\n","    predicted_label = np.argmax(prediction, axis=1)[0]\n","    return 'Non Hate Speech' if predicted_label == 1 else 'Hate Speech'"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["this movie is the worst, anyone who likes the movie is an asshole\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","The input text is classified as: Hate Speech\n","Just watched the latest release, and it was amazing! Can’t wait to see it again\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","The input text is classified as: Non Hate Speech\n","personally i dont like the movie, but it might be okay for others\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","The input text is classified as: Non Hate Speech\n","shit movie, shit actors, omg i cant believe i watched this #$$%$^^ movie from the theatre\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","The input text is classified as: Hate Speech\n"]}],"source":["for i in range(0, 4):\n","\n","\n","    input_text = str(input(\"Enter the text to predict : \"))\n","    print(input_text)\n","    prediction = predict_text(input_text)\n","    print(f\"The input text is classified as: {prediction}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
