{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  woman shouldnt complain cleaning house man alw...  \n",
      "1          boy that coldtyga bad cuffin hoe st place  \n",
      "2       dawg ever fuck bitch start cry confused shit  \n",
      "3                                   look like tranny  \n",
      "4        shit hear might true might faker bitch told  \n",
      "\n",
      "Last 5 rows of the dataset:\n",
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "24761       25291      3            0                   2        1      1   \n",
      "24762       25292      3            0                   1        2      2   \n",
      "24763       25294      3            0                   3        0      1   \n",
      "24764       25295      6            0                   6        0      1   \n",
      "24765       25296      3            0                   0        3      2   \n",
      "\n",
      "                                                   tweet  \n",
      "24761  yous muthafin lie right tl trash mine bible sc...  \n",
      "24762  youve gone broke wrong heart baby drove rednec...  \n",
      "24763   young buck wanna eat nigguh like aint fuckin dis  \n",
      "24764                     youu got wild bitch tellin lie  \n",
      "24765  ruffled ntac eileen dahlia beautiful color com...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the last few rows of the dataset\n",
    "print(\"\\nLast 5 rows of the dataset:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows after tokenization:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  woman shouldnt complain cleaning house man alw...   \n",
      "1          boy that coldtyga bad cuffin hoe st place   \n",
      "2       dawg ever fuck bitch start cry confused shit   \n",
      "3                                   look like tranny   \n",
      "4        shit hear might true might faker bitch told   \n",
      "\n",
      "                                        tweet_tokens  \n",
      "0  [woman, shouldnt, complain, cleaning, house, m...  \n",
      "1  [boy, that, coldtyga, bad, cuffin, hoe, st, pl...  \n",
      "2  [dawg, ever, fuck, bitch, start, cry, confused...  \n",
      "3                               [look, like, tranny]  \n",
      "4  [shit, hear, might, true, might, faker, bitch,...  \n",
      "\n",
      "Last 5 rows after tokenization:\n",
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "24761       25291      3            0                   2        1      1   \n",
      "24762       25292      3            0                   1        2      2   \n",
      "24763       25294      3            0                   3        0      1   \n",
      "24764       25295      6            0                   6        0      1   \n",
      "24765       25296      3            0                   0        3      2   \n",
      "\n",
      "                                                   tweet  \\\n",
      "24761  yous muthafin lie right tl trash mine bible sc...   \n",
      "24762  youve gone broke wrong heart baby drove rednec...   \n",
      "24763   young buck wanna eat nigguh like aint fuckin dis   \n",
      "24764                     youu got wild bitch tellin lie   \n",
      "24765  ruffled ntac eileen dahlia beautiful color com...   \n",
      "\n",
      "                                            tweet_tokens  \n",
      "24761  [yous, muthafin, lie, right, tl, trash, mine, ...  \n",
      "24762  [youve, gone, broke, wrong, heart, baby, drove...  \n",
      "24763  [young, buck, wan, na, eat, nigguh, like, aint...  \n",
      "24764              [youu, got, wild, bitch, tellin, lie]  \n",
      "24765  [ruffled, ntac, eileen, dahlia, beautiful, col...  \n"
     ]
    }
   ],
   "source": [
    "df[text_column] = df[text_column].astype(str)\n",
    "# Tokenize the text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def tokenize_data(df, text_column):\n",
    "    \"\"\"\n",
    "    Apply the tokenize_text function to a specific column in the DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    df[text_column + '_tokens'] = df[text_column].apply(tokenize_text)\n",
    "    return df\n",
    "\n",
    "# Define the text column\n",
    "text_column = 'tweet'\n",
    "\n",
    "# Tokenize the text data\n",
    "df = tokenize_data(df, text_column)\n",
    "\n",
    "# Display the first few rows of the tokenized data\n",
    "print(\"First 5 rows after tokenization:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the last few rows of the tokenized data\n",
    "print(\"\\nLast 5 rows after tokenization:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (24766, 18144)\n",
      "First 5 feature names: ['aa' 'aaaaaaaaand' 'aaahhhhh' 'aahahah' 'aaliyah']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF encoding\n",
    "def tfidf_encoding(df, text_column):\n",
    "    \"\"\"\n",
    "    Apply TF-IDF encoding to a specific column in the DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df[text_column])\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    return tfidf_matrix, feature_names\n",
    "\n",
    "# Apply TF-IDF encoding\n",
    "tfidf_matrix, feature_names = tfidf_encoding(df, text_column)\n",
    "\n",
    "# Display the shape of the TF-IDF matrix\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)\n",
    "\n",
    "# Display the first 5 feature names\n",
    "print(\"First 5 feature names:\", feature_names[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF encoded data saved to tfidf_encoded_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to save the TF-IDF matrix and the original dataframe\n",
    "data_to_save = {\n",
    "    'tfidf_matrix': tfidf_matrix,\n",
    "    'feature_names': feature_names,\n",
    "    'original_data': df[['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither', 'class', 'tweet']]\n",
    "}\n",
    "\n",
    "# Save the dictionary to a  pickle file\n",
    "with open('tfidf_encoded_data.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "print(\"TF-IDF encoded data saved to tfidf_encoded_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loaded TF-IDF matrix: (24766, 18144)\n",
      "First 5 feature names: ['aa' 'aaaaaaaaand' 'aaahhhhh' 'aahahah' 'aaliyah']\n",
      "First 5 rows of the original data:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  woman shouldnt complain cleaning house man alw...  \n",
      "1          boy that coldtyga bad cuffin hoe st place  \n",
      "2       dawg ever fuck bitch start cry confused shit  \n",
      "3                                   look like tranny  \n",
      "4        shit hear might true might faker bitch told  \n"
     ]
    }
   ],
   "source": [
    "# Load the Pickle file\n",
    "with open('tfidf_encoded_data.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Extract the TF-IDF matrix, feature names, and original data from the loaded dictionary\n",
    "tfidf_matrix_loaded = loaded_data['tfidf_matrix']\n",
    "feature_names_loaded = loaded_data['feature_names']\n",
    "original_data_loaded = loaded_data['original_data']\n",
    "\n",
    "# Display the shape of the loaded TF-IDF matrix and the first 5 feature names\n",
    "print(f\"Shape of loaded TF-IDF matrix: {tfidf_matrix_loaded.shape}\")\n",
    "print(f\"First 5 feature names: {feature_names_loaded[:5]}\")\n",
    "\n",
    "# Display the first few rows of the original data\n",
    "print(\"First 5 rows of the original data:\")\n",
    "print(original_data_loaded.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
